# Research and Validation (IA)

Use lightweight methods to validate findability *before* committing to a complex re-org.

## Tree Testing (findability)
**Goal:** validate whether users can find key destinations in a proposed hierarchy.

1) Pick 8–12 critical tasks (real wording from users/support tickets).
2) Present the navigation tree (no UI polish, just structure).
3) Ask: “Where would you go to do X?”
4) Measure:
  - first click accuracy
  - time to decide
  - common wrong branches
5) Iterate labels and groupings, then re-test the top failures.

**What it catches:** wrong buckets, ambiguous labels, over-deep nesting.

## Card Sorting (category discovery)
**Goal:** discover how users group concepts and what they call them.

- **Open card sort**: users create categories (best early).
- **Closed card sort**: users sort into your categories (best for validation).
- **Hybrid**: categories exist but users can rename/suggest new ones.

Tips:
- Use 30–50 cards max per session; split if needed.
- Seed with the most common content/features, not edge cases.
- Capture proposed labels verbatim; that’s gold for navigation copy.

## First-Click Testing (fast UI + IA feedback)
**Goal:** validate the first step in a flow (often driven by IA labels).

- Present a simple wireframe or even a plain list of links.
- Ask “Where would you click first to…?”
- Wrong first clicks usually indicate: unclear labels, wrong grouping, or competing CTAs.

## IA Audit Checklist (quick scan)
- Top-level nav items are mutually understandable and not overlapping.
- Labels are consistent and match page titles.
- No “misc”, “other”, “stuff”, “tools” dumping grounds without a purpose statement.
- Settings are split by scope (user vs workspace vs org) and risk (safe vs dangerous).
- Search and nav complement each other; neither is overloaded.

## Using Analytics and Search Logs
Use evidence to reduce bikeshedding:
- **Most visited destinations** per role
- **Most common search queries** and “no results” queries
- **Paths** to critical outcomes (where users drop off)
- **Support tickets** tagged “can’t find” / “confusing”

## Participant Guidance
- 5–8 participants per key persona often surfaces the big IA issues.
- Bias toward *representative roles* over total headcount.
- Keep sessions short (20–30 minutes) to stay focused on findability.

